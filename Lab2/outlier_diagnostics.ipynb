{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Group = \"\" #G1\n",
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4d3e62f377d4667860f853482eaccc12",
     "grade": false,
     "grade_id": "cell-6f484ebfdd304c6c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This notebook provides: \n",
    "\n",
    "- [Tools and packages](#tools-and-packages) \n",
    "    - [Data processing](#data-loading-preprocessing-and-visualization)\n",
    "- [Outlier analysis](#outlier-analysis)\n",
    "    - [H-matrix](#h-matrix)   \n",
    "    - [Cook's distance](#cooks-distance)\n",
    "- Your tasks are to compair and discuss the difference between these methods\n",
    "    - [Performance compairison](#performance-compairison)\n",
    "    - [Are the outliers of the two methods intersect](#are-the-outliers-of-the-two-methods-intersect)\n",
    "    - [How is the performance improved by the two outlier removals](#how-is-the-performance-improvement-by-the-two-outlier-removals)\n",
    "\n",
    "You can run this notebook on collab:  <a target=\"_blank\" href=\"https://colab.research.google.com/github/GenAI-CUEE/Statistical-Learning-EE575-Y2024/blob/master/Lab2/outlier_diagnostics.ipynb\"> <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn import metrics  \n",
    "import seaborn as sns\n",
    "\n",
    "def train_validate_test_split(df, train_percent=.6, validate_percent=.2, seed=None):\n",
    "    np.random.seed(seed) \n",
    "    perm         = np.random.permutation(df.index)\n",
    "    m            = len(df.index) \n",
    "    train_end    = np.floor(int(train_percent * m))\n",
    "    validate_end = np.floor(int(validate_percent * m) + train_end) \n",
    "    \n",
    "    train        = df.iloc[perm[:train_end]]\n",
    "    validate     = df.iloc[perm[train_end:validate_end]]\n",
    "    test         = df.iloc[perm[validate_end:]] \n",
    "\n",
    "    train       = train.drop(columns=[\"index\"])\n",
    "    validate    = validate.drop(columns=[\"index\"])\n",
    "    test        = test.drop(columns=[\"index\"])\n",
    "\n",
    "    train       = train.reset_index(drop=True)\n",
    "    validate    = validate.reset_index(drop=True)\n",
    "    test        = test.reset_index(drop=True)\n",
    "    \n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldername = \"house-prices-advanced-regression-techniques\"\n",
    "df = pd.read_csv('%s/train.csv' % foldername)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading, preprocessing, and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = [\"SalePrice\"]\n",
    "feat_column   = [  \"MoSold\",        \"YrSold\",        \"MSZoning\",     \"LandSlope\",   \"2ndFlrSF\",  \"CentralAir\",    \"TotRmsAbvGrd\",  \"TotalBsmtSF\",  \"GrLivArea\",   \"BldgType\",    \"OverallCond\",   \"BsmtHalfBath\",  \"ScreenPorch\" ] \n",
    "\n",
    "all_column = target_column + feat_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[all_column]\n",
    "df = df.apply(LabelEncoder().fit_transform)\n",
    "\n",
    "df = df.dropna() \n",
    "df = df.reset_index()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = train_validate_test_split(df, train_percent=.8, validate_percent=.1, seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = StandardScaler() \n",
    "train[feat_column].values[:]        = X_scaler.fit_transform(train[feat_column].values[:] )\n",
    "test[feat_column].values[:]         = X_scaler.transform(test[feat_column].values[:] )\n",
    "valid[feat_column].values[:]        = X_scaler.transform(valid[feat_column].values[:] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_column =  target_column + feat_column\n",
    "train_enc    = train.loc[:,data_column] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "cor = train_enc.corr()\n",
    "g = sns.heatmap(cor, annot=True, cmap=plt.cm.cool) \n",
    "g.axes.xaxis.set_ticks_position(\"top\")\n",
    "plt.setp(g.axes.get_xticklabels(), rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = [\"SalePrice\"]\n",
    "feat_column   = [\"GrLivArea\"]\n",
    "outliers_percentile = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H-matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $X$ be an array of training data. Then, H-matrix is defined by \n",
    "$$ H = X (X^T X)^{-1} X^T $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the function `H_matrix_leverage() ` using `X_train` to compute the diagonal entries of the H matrix.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd7988019e24806933de87f822a844b0",
     "grade": false,
     "grade_id": "HMatrix",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def H_matrix_leverage(X_train):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return H_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "95b864498176c2ee2923a8691a50e54e",
     "grade": true,
     "grade_id": "HMatrixTest",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_train   = train.loc[:,feat_column].values\n",
    "[num_samples, num_feats]     = X_train.shape\n",
    "\n",
    "H_diag = H_matrix_leverage(X_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot diagonal entries of hat matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_H = np.percentile(H_diag, 100-outliers_percentile)\n",
    "\n",
    "plt.figure(figsize=(20,5)) \n",
    "plt.plot(H_diag, marker=\"o\", ls='none')\n",
    "plt.hlines(p_H, xmin=0, xmax=len(H_diag), colors=\"red\")\n",
    "plt.xlabel(\"$i^{th}$ sample\")\n",
    "plt.ylabel(\"diagonal of hat matrix\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cook's distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each entry in the Cook's distance vector is defined by \n",
    "$$ D_j = \\frac{e^2_j \\cdot h_{j,j}}{n \\cdot \\text{MSE}_{y}(\\hat{y}) \\cdot (1-h_{j,j})^2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where each components are calculated using the following variables:\n",
    "\n",
    "$[h_{j,j}]_{j = 1:m}$ := `H_diag`\n",
    "\n",
    "$[e^2_j]_{j = 1:m}$ := `e_train`\n",
    "\n",
    "$\\text{MSE}_{y}(\\hat{y})$ := `mse_train`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will provide `e_train` and `mse_train` for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression \n",
    "\n",
    "X_train = train[feat_column].values\n",
    "y_train = train[target_column].values\n",
    "\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X_train, y_train) \n",
    "\n",
    "y_train_predict = model_lr.predict(X_train) \n",
    "\n",
    "e_train = (y_train - y_train_predict).reshape(-1)\n",
    "mse_train = np.mean((y_train - y_train_predict)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the function `CookDistance()` using `e_train, mse_train, H_diag, num_feats` to compute Cook's distance vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36aba80d3b589188ff031f67a1f895e3",
     "grade": false,
     "grade_id": "CookDistance",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def CookDistance(e_train, mse_train, H_diag, num_feats):  \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return Cook_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "785c69b49e3fc335f74216634867e262",
     "grade": true,
     "grade_id": "CookDistanceTest",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "Cook_D = CookDistance(e_train, mse_train, H_diag, num_feats) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Cook's distance entries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_D = np.percentile(Cook_D, 100-outliers_percentile)\n",
    "\n",
    "plt.figure(figsize=(20,5)) \n",
    "plt.plot(Cook_D, marker=\"o\", ls='none')\n",
    "plt.hlines(p_D, xmin=0, xmax=len(Cook_D), colors=\"red\")\n",
    "plt.xlabel(\"$i^{th}$ sample\")\n",
    "plt.ylabel(\"diagonal of hat matrix\")\n",
    "plt.ylim([-0.01,0.10])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance compairison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Are the outliers of the two methods intersect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_H  = X_train[H_diag <= p_H, :]\n",
    "Y_train_H  = y_train[H_diag <= p_H]\n",
    "\n",
    "X_train_H_outliers  = X_train[H_diag > p_H, :]\n",
    "Y_train_H_outliers  = y_train[H_diag > p_H]\n",
    "\n",
    "\n",
    "X_train_Cooks  = X_train[Cook_D <= p_D, :]\n",
    "Y_train_Cooks  = y_train[Cook_D <= p_D]\n",
    "X_train_Cooks_outliers  = X_train[Cook_D > p_D, :]\n",
    "Y_train_Cooks_outliers  = y_train[Cook_D > p_D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5)) \n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(X_train_H, Y_train_H, color=\"red\",  marker=\"o\", label='H-matrix', s=50, alpha=0.5)\n",
    "plt.scatter(X_train_H_outliers, Y_train_H_outliers, color=\"orange\",  marker=\"+\", label='H-matrix outliers', s=50, alpha=0.5)\n",
    "plt.legend(bbox_to_anchor=(0.50, 1.1), ncol=2)\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(X_train_Cooks, Y_train_Cooks, color=\"blue\",  label='Cook''s', alpha=0.5)  \n",
    "plt.scatter(X_train_Cooks_outliers, Y_train_Cooks_outliers, color=\"cyan\",  marker=\"+\", label='Cook''s outliers',   alpha=0.5)\n",
    "plt.xlabel(\"\")\n",
    "plt.legend(bbox_to_anchor=(0.50, 1.1), ncol=2)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How is the performance improvement by the two outlier removals?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test[feat_column].values\n",
    "y_test = test[target_column].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_test = model_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After outlier removal by H-matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr_H = LinearRegression()\n",
    "model_lr_H.fit(X_train_H, Y_train_H)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_H_test = model_lr_H.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After outlier removal by Cook's distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr_D = LinearRegression()\n",
    "model_lr_D.fit(X_train_Cooks, Y_train_Cooks)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_D_test = model_lr_D.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_before = np.sqrt(np.mean((y_predict_test - y_test)**2)) \n",
    "MSE_after_H = np.sqrt(np.mean((y_predict_H_test - y_test)**2))\n",
    "MSE_after_D = np.sqrt(np.mean((y_predict_D_test - y_test)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MSE [before] = %.2f\" % MSE_before)\n",
    "print(\"MSE [after using H-matrix]     = %.2f\" % MSE_after_H)\n",
    "print(\"MSE [after using Cook's Dist.] = %.2f\" % MSE_after_D) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5)) \n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(X_train_H, Y_train_H, color=\"red\",  marker=\"o\", label='H-matrix', s=50, alpha=0.5)\n",
    "plt.scatter(X_train_H_outliers, Y_train_H_outliers, color=\"orange\",  marker=\"+\", label='H-matrix outliers', s=50, alpha=0.5)\n",
    "plt.scatter(X_test, y_test, color=\"grey\",  marker=\"o\", label='Test', s=50, alpha=0.5)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(0.50, 1.1), ncol=3)\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(X_train_Cooks, Y_train_Cooks, color=\"blue\",  label='Cook''s', alpha=0.5)  \n",
    "plt.scatter(X_train_Cooks_outliers, Y_train_Cooks_outliers, color=\"cyan\",  marker=\"+\", label='Cook''s outliers',   alpha=0.5)\n",
    "plt.scatter(X_test, y_test, color=\"grey\",  marker=\"o\", label='Test', s=50, alpha=0.5)\n",
    "\n",
    "plt.xlabel(\"\")\n",
    "plt.legend(bbox_to_anchor=(0.50, 1.1), ncol=3)\n",
    "plt.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EE575",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
